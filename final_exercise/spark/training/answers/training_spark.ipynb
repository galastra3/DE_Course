{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e30b104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/03 00:22:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/07/03 00:22:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b9afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = spark.read.options(inferSchema='True', delimiter='\\t').text(\"./data/sentiment/imdb_labelled.txt\")\n",
    "df_amazon = spark.read.text(\"./data/sentiment/amazon_cells_labelled.txt\")\n",
    "df_yelp = spark.read.text(\"./data/sentiment/yelp_labelled.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279bdf38",
   "metadata": {},
   "source": [
    "- In the `readme.txt` file (the same directory where the data are), read how to parse the text.\n",
    "- - Hint: You might want to use `map`.\n",
    "- Union all the three dataframes to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7346f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                text|target|\n",
      "+--------------------+------+\n",
      "|A very, very, ver...|     0|\n",
      "|Not sure who was ...|     0|\n",
      "|Attempting artine...|     0|\n",
      "|Very little music...|     0|\n",
      "|The best scene in...|     1|\n",
      "|The rest of the m...|     0|\n",
      "| Wasted two hours.  |     0|\n",
      "|Saw the movie tod...|     1|\n",
      "|A bit predictable.  |     0|\n",
      "|Loved the casting...|     1|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = df_imdb.union(df_amazon).union(df_yelp)\n",
    "# df_raw = df_raw.map(lambda row: row.split('\\t'))\n",
    "# rdd = spark.sparkContext.parallelize(df_raw)\n",
    "# split_rdd = rdd.map(lambda x: x.split('\\t'))\n",
    "split_rdd = df_raw.rdd.map(lambda x: x.value.split('\\t'))\n",
    "df_raw = split_rdd.toDF(['text', 'target'])\n",
    "df_raw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9123a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you split to train and test\n",
    "(train_set, test_set) = df_raw.randomSplit([0.9, 0.1], seed=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a39c5",
   "metadata": {},
   "source": [
    "After we split to train and test, we will build a pipeline to extract the features from the text.\n",
    "\n",
    "If you remember from the lectures, you can't do analysis on the words themselves, since they have no information.\n",
    "\n",
    "So, we need to have an informative feature for the words.\n",
    "\n",
    "We will choose counting as a basic feature that works.\n",
    "\n",
    "_(Meaning that the value of the word will be the count of how many times it occurs in the dataset)_\n",
    "\n",
    "So, we will use [`pyspark.ml.feature.CountVectorizer`](https://spark.apache.org/docs/latest/ml-features#countvectorizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9ed42",
   "metadata": {},
   "source": [
    "But first, we need to split the words.\n",
    "And we want to do it smart, not just by `.split()`.\n",
    "\n",
    "So, we will use [`pyspark.ml.feature.Tokenizer`](https://spark.apache.org/docs/latest/ml-features#tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5ba960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StringIndexer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "counter = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol=\"features\")\n",
    "label_stringIdx = StringIndexer(inputCol=\"target\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cb692",
   "metadata": {},
   "source": [
    "Next, we will use [`pyspark.ml.classification.LogisticRegression`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html) for our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcddcc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2b0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `pyspark.ml.pipeline` of the feature extractors and the model.\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, counter, label_stringIdx,  lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f379aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/03 00:22:20 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "22/07/03 00:22:21 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/07/03 00:22:21 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/07/03 00:22:21 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/07/03 00:22:21 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "+--------------------+------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|                text|target|               words|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|\" But \"Storm Troo...|     0|[\", but, \"storm, ...|(6844,[0,4,5,6,9,...|  1.0|[-65.685406804100...|[2.97296833388740...|       1.0|\n",
      "|      \" I love it.  |     1|   [\", i, love, it.]|(6844,[2,46,88,64...|  0.0|[42.0071166498453...|           [1.0,0.0]|       0.0|\n",
      "|\" In fact, it's h...|     1|[\", in, fact,, it...|(6844,[0,1,4,5,6,...|  0.0|[22.1022497173129...|[0.99999999974816...|       0.0|\n",
      "|\" The structure o...|     1|[\", the, structur...|(6844,[0,4,6,7,10...|  0.0|[34.9519810843670...|[0.99999999999999...|       0.0|\n",
      "|\" With great soun...|     1|[\", with, great, ...|(6844,[1,2,7,14,2...|  0.0|[58.3484099877297...|           [1.0,0.0]|       0.0|\n",
      "+--------------------+------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model on the train\n",
    "# (like we did with the ML exercises earlier in the course)\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "test_df = pipelineFit.transform(test_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988e190",
   "metadata": {},
   "source": [
    "We need some benchmarks to understand how well is our model.\n",
    "\n",
    "We'll use [`pyspark.ml.evaluation.BinaryClassificationEvaluator`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.BinaryClassificationEvaluator.html) to evaluate the model on train and on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4691ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8682583304706284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# continue...\n",
    "\n",
    "\n",
    "# accuracy = \n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24670f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipelineFit.save('./best_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd8f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
